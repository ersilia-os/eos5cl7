{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTvyzBfNWavQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import lazyqsar as lq\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATAPATH = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "apvdFbJkD8Tc"
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(DATAPATH,\"Data.csv\")\n",
    "Data = pd.read_csv(filename)\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DhNGnvO5559K"
   },
   "outputs": [],
   "source": [
    "SMILES = \"SMILES\"\n",
    "ACTIVE = \"Active\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xmKsGu5VLv2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = Data[ACTIVE]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvjgNIsvVz0W"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(x=x, data=Data)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='bottom')\n",
    "plt.xlabel('Active')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()\n",
    "\n",
    "activity_counts = Data['Active'].value_counts()\n",
    "print(activity_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "du1QeKC2oMWa"
   },
   "outputs": [],
   "source": [
    "desc = Data['SMILES']\n",
    "y = Data['Active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-EK-MCpoh-C"
   },
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJTIUgTPEfg2"
   },
   "source": [
    "#  Training with Train-test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5lbCuwsva3X"
   },
   "source": [
    "# **Morgan BinaryClassifier_60**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "6pAHfSxujCcf",
    "outputId": "c2173592-f68a-4497-8a6c-93abab6b5ac0"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Generate your own train_test_split using the code below\n",
    "  Uncomment to use\n",
    "\"\"\"\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# for i, (train, test) in enumerate(cv.split(desc, y)):\n",
    "#     # Store training and testing sets for the current fold\n",
    "#     train_set = pd.DataFrame(desc.iloc[train])\n",
    "#     test_set = pd.DataFrame(desc.iloc[test])\n",
    "\n",
    "#     # Add the Activity column to both training and testing sets\n",
    "#     train_set['Active'] = y[train]\n",
    "#     test_set['Active'] = y[test]\n",
    "\n",
    "#     # Save the combined training and testing sets for the current fold\n",
    "#     train_file = f\"train_{i}.csv\"\n",
    "#     test_file = f\"test_{i}.csv\"\n",
    "#     train_set.to_csv(train_file, index=False)\n",
    "#     test_set.to_csv(test_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "v7AE6Qh1AlQo",
    "outputId": "d5ecf050-48fa-423a-cc36-eb3b5bdc6512"
   },
   "outputs": [],
   "source": [
    "# Define SMILES and EXP variables if not defined\n",
    "SMILES = 'SMILES'\n",
    "EXP = 'Active'\n",
    "\n",
    "# Assuming 'desc' and 'y' are your input data\n",
    "# Initialize AutoML for classification task\n",
    "model = lq.MorganBinaryClassifier(time_budget_sec=60, estimator_list=[\"rf\", \"lgbm\", \"xgboost\"])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "train_sets = []\n",
    "test_sets = []\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_true_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    train_file = f\"train_{i}.csv\"\n",
    "    test_file = f\"test_{i}.csv\"\n",
    "    train_set = pd.read_csv(train_file)\n",
    "    test_set = pd.read_csv(test_file)\n",
    "    smiles_train = train_set['SMILES']\n",
    "    print(smiles_train)\n",
    "    print(y_train)\n",
    "    y_train = train_set[EXP]\n",
    "\n",
    "    # Append training and testing sets to the lists\n",
    "    train_sets.append(train_set)\n",
    "    test_sets.append(test_set)\n",
    "\n",
    "    # Fit the model on the training set for the current fold\n",
    "    model.fit(smiles_train, y_train)\n",
    "\n",
    "    # Obtain predictions and true labels for the current fold\n",
    "    y_hat_proba = model.predict_proba(test_set[SMILES])[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(test_set[EXP], y_hat_proba)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "    y_pred = model.predict(test_set[SMILES])\n",
    "    true_labels = test_set[EXP]\n",
    "\n",
    "    # Append the training and testing sets for the current fold to the lists\n",
    "    train_sets.append(train_set)\n",
    "    test_sets.append(test_set)\n",
    "\n",
    "    # Classification report for the current fold\n",
    "    print(f\"\\nClassification Report for Fold {i}:\\n\")\n",
    "    print(classification_report(true_labels, y_pred))\n",
    "\n",
    "    # Accumulate true labels and predictions\n",
    "    all_true_labels.extend(test_set[EXP])\n",
    "    all_predictions.extend(y_pred)\n",
    "\n",
    "# Calculate and print the average classification report\n",
    "print(\"\\nAverage Classification Report Across All Folds:\\n\")\n",
    "print(classification_report(all_true_labels, all_predictions))\n",
    "\n",
    "# Calculate mean ROC curve and AUC\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "# Plot mean ROC curve with boundaries\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Cross-Validation ROC of AutoML', fontsize=18)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 15})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHW150tTIv49"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "model_name = 'MorganBinaryClassifier_60'\n",
    "print(f\"-------- {model_name} Confusion Matrix --------\")\n",
    "conf_mat =  confusion_matrix(y[test], y_pred)\n",
    "ax = sns.heatmap(conf_mat, annot=True, cmap='Greens', cbar=False, annot_kws={\"size\": 16})\n",
    "ax.set_title(\"Predicted vs Real\", fontsize=14)\n",
    "ax.set_xlabel('Predicted', fontsize=14)\n",
    "ax.set_ylabel('Real', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayZa7heZvi7A"
   },
   "source": [
    "# **MorganBinaryClassifier_600**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZpcMmmyqn-C"
   },
   "outputs": [],
   "source": [
    "# Define SMILES and EXP variables if not defined\n",
    "SMILES = 'SMILES'\n",
    "EXP = 'Active'\n",
    "\n",
    "# Assuming 'desc' and 'y' are your input data\n",
    "# Initialize AutoML for classification task\n",
    "model = lq.MorganBinaryClassifier(time_budget_sec=600, estimator_list=[\"rf\", \"lgbm\", \"xgboost\"])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "train_sets = []\n",
    "test_sets = []\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_true_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    train_file = f\"train_{i}.csv\"\n",
    "    test_file = f\"test_{i}.csv\"\n",
    "    train_set = pd.read_csv(train_file)\n",
    "    test_set = pd.read_csv(test_file)\n",
    "    smiles_train = train_set['SMILES']\n",
    "    y_train = train_set[EXP]\n",
    "\n",
    "    # Append training and testing sets to the lists\n",
    "    train_sets.append(train_set)\n",
    "    test_sets.append(test_set)\n",
    "\n",
    "    # Fit the model on the training set for the current fold\n",
    "    model.fit(smiles_train, y_train)\n",
    "\n",
    "    # Obtain predictions and true labels for the current fold\n",
    "    y_hat_proba = model.predict_proba(test_set[SMILES])[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(test_set[EXP], y_hat_proba)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "    y_pred = model.predict(test_set[SMILES])\n",
    "    true_labels = test_set[EXP]\n",
    "\n",
    "    # Append the training and testing sets for the current fold to the lists\n",
    "    train_sets.append(train_set)\n",
    "    test_sets.append(test_set)\n",
    "\n",
    "    # Classification report for the current fold\n",
    "    print(f\"\\nClassification Report for Fold {i}:\\n\")\n",
    "    print(classification_report(true_labels, y_pred))\n",
    "\n",
    "    # Accumulate true labels and predictions\n",
    "    all_true_labels.extend(test_set[EXP])\n",
    "    all_predictions.extend(y_pred)\n",
    "\n",
    "# Calculate and print the average classification report\n",
    "print(\"\\nAverage Classification Report Across All Folds:\\n\")\n",
    "print(classification_report(all_true_labels, all_predictions))\n",
    "\n",
    "# Calculate mean ROC curve and AUC\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "# Plot mean ROC curve with boundaries\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Cross-Validation ROC of AutoML', fontsize=18)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 15})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvZxBwH8MFjS"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "model_name = 'MorganBinaryClassifier_600'\n",
    "print(f\"-------- {model_name} Confusion Matrix --------\")\n",
    "conf_mat =  confusion_matrix(test_set[EXP], y_pred)\n",
    "ax = sns.heatmap(conf_mat, annot=True, cmap='Greens', cbar=False, annot_kws={\"size\": 16})\n",
    "ax.set_title(\"Predicted vs Real\", fontsize=14)\n",
    "ax.set_xlabel('Predicted', fontsize=14)\n",
    "ax.set_ylabel('Real', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLO0Qgj22Y6U"
   },
   "source": [
    "# **ErsiliaBinaryClassifier_60**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvsqctotvpZX"
   },
   "outputs": [],
   "source": [
    "# Define SMILES and EXP variables if not defined\n",
    "SMILES = 'SMILES'\n",
    "EXP = 'Active'\n",
    "\n",
    "# Assuming 'desc' and 'y' are your input data\n",
    "# Initialize AutoML for classification task\n",
    "model = lq.ErsiliaBinaryClassifier(time_budget_sec=60, estimator_list=[\"rf\", \"lgbm\", \"xgboost\"])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "train_sets = []\n",
    "test_sets = []\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_true_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "\n",
    "#for i, (train, test) in enumerate(cv.split(desc, y)):\n",
    "for i in range(5):\n",
    "    train_file = f\"train_{i}.csv\"\n",
    "    test_file = f\"test_{i}.csv\"\n",
    "    train_set = pd.read_csv(train_file)\n",
    "    test_set = pd.read_csv(test_file)\n",
    "    smiles_train = train_set['SMILES']\n",
    "    y_train = train_set[EXP]\n",
    "\n",
    "    # Append training and testing sets to the lists\n",
    "    train_sets.append(train_set)\n",
    "    test_sets.append(test_set)\n",
    "\n",
    "    # Fit the model on the training set for the current fold\n",
    "    model.fit(smiles_train, y_train)\n",
    "\n",
    "    # Obtain predictions and true labels for the current fold\n",
    "    y_hat_proba = model.predict_proba(test_set[SMILES])[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(test_set[EXP], y_hat_proba)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "    y_pred = model.predict(test_set[SMILES])\n",
    "    true_labels = test_set[EXP]\n",
    "\n",
    "    # Append the training and testing sets for the current fold to the lists\n",
    "    train_sets.append(train_set)\n",
    "    test_sets.append(test_set)\n",
    "\n",
    "    # Classification report for the current fold\n",
    "    print(f\"\\nClassification Report for Fold {i}:\\n\")\n",
    "    print(classification_report(true_labels, y_pred))\n",
    "\n",
    "    # Accumulate true labels and predictions\n",
    "    all_true_labels.extend(test_set[EXP])\n",
    "    all_predictions.extend(y_pred)\n",
    "\n",
    "# Calculate and print the average classification report\n",
    "print(\"\\nAverage Classification Report Across All Folds:\\n\")\n",
    "print(classification_report(all_true_labels, all_predictions))\n",
    "\n",
    "# Calculate mean ROC curve and AUC\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "# Plot mean ROC curve with boundaries\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Cross-Validation ROC of AutoML', fontsize=18)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 15})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tC40D5AXtYt"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "model_name = 'ErsiliaBinaryClassifier_60'\n",
    "print(f\"-------- {model_name} Confusion Matrix --------\")\n",
    "conf_mat =  confusion_matrix(test_set[EXP], y_pred)\n",
    "ax = sns.heatmap(conf_mat, annot=True, cmap='Greens', cbar=False, annot_kws={\"size\": 16})\n",
    "ax.set_title(\"Predicted vs Real\", fontsize=14)\n",
    "ax.set_xlabel('Predicted', fontsize=14)\n",
    "ax.set_ylabel('Real', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZxdDIM53u_T"
   },
   "source": [
    "# **ErsiliaBinaryClassifier_600**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWWQQAk-wdjR"
   },
   "outputs": [],
   "source": [
    "# Define SMILES and EXP variables if not defined\n",
    "SMILES = 'SMILES'\n",
    "EXP = 'Active'\n",
    "\n",
    "# Assuming 'desc' and 'y' are your input data\n",
    "# Initialize AutoML for classification task\n",
    "model = lq.ErsiliaBinaryClassifier(time_budget_sec=600, estimator_list=[\"rf\", \"lgbm\", \"xgboost\"])\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "train_sets = []\n",
    "test_sets = []\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_true_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "\n",
    "#for i, (train, test) in enumerate(cv.split(desc, y)):\n",
    "for i in range(5):\n",
    "    train_file = f\"train_{i}.csv\"\n",
    "    test_file = f\"test_{i}.csv\"\n",
    "    train_set = pd.read_csv(train_file)\n",
    "    test_set = pd.read_csv(test_file)\n",
    "    smiles_train = train_set['SMILES']\n",
    "    y_train = train_set[EXP]\n",
    "\n",
    "    # Append training and testing sets to the lists\n",
    "    train_sets.append(train_set)\n",
    "    test_sets.append(test_set)\n",
    "\n",
    "    # Fit the model on the training set for the current fold\n",
    "    model.fit(smiles_train, y_train)\n",
    "\n",
    "    # Obtain predictions and true labels for the current fold\n",
    "    y_hat_proba = model.predict_proba(test_set[SMILES])[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(test_set[EXP], y_hat_proba)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "    y_pred = model.predict(test_set[SMILES])\n",
    "    true_labels = test_set[EXP]\n",
    "\n",
    "    # Append the training and testing sets for the current fold to the lists\n",
    "    train_sets.append(train_set)\n",
    "    test_sets.append(test_set)\n",
    "\n",
    "    # Classification report for the current fold\n",
    "    print(f\"\\nClassification Report for Fold {i}:\\n\")\n",
    "    print(classification_report(true_labels, y_pred))\n",
    "\n",
    "    # Accumulate true labels and predictions\n",
    "    all_true_labels.extend(test_set[EXP])\n",
    "    all_predictions.extend(y_pred)\n",
    "\n",
    "# Calculate and print the average classification report\n",
    "print(\"\\nAverage Classification Report Across All Folds:\\n\")\n",
    "print(classification_report(all_true_labels, all_predictions))\n",
    "\n",
    "# Calculate mean ROC curve and AUC\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "# Plot mean ROC curve with boundaries\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Cross-Validation ROC of AutoML', fontsize=18)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 15})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCNgDU-XZAtF"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "model_name = 'ErsiliaBinaryClassifier_600'\n",
    "print(f\"-------- {model_name} Confusion Matrix --------\")\n",
    "conf_mat =  confusion_matrix(test_set[EXP], y_pred)\n",
    "ax = sns.heatmap(conf_mat, annot=True, cmap='Greens', cbar=False, annot_kws={\"size\": 16})\n",
    "ax.set_title(\"Predicted vs Real\", fontsize=14)\n",
    "ax.set_xlabel('Predicted', fontsize=14)\n",
    "ax.set_ylabel('Real', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdOR_yx7_1vo"
   },
   "source": [
    "The model using ErsiliaBinaryClassifier and train time of 600 performed well than the other models. This is because as seen in the AUC-ROC curve. It has the highest mean AUC value (0.78) and the smallest standard deviation (0.08) for the 5-fold cross-validation. This indicates that the model has consistently performed well across all five folds of the cross-validation, suggesting better generalization ability compared to the other models.\n",
    "\n",
    "The other three models have lower mean AUC values (0.75, 0.74, and 0.75) and larger standard deviations (0.10, 0.07, and 0.03), which indicates more variability in performance across the folds. This could be due to overfitting or other issues with the model.\n",
    "\n",
    "In general, a lower standard deviation for the AUC ROC curve indicates greater consistency in model performance across different data splits. Therefore, the Mean ROC (AUC=0.78 +- 0.08) is the best model based on these metrics.\n",
    "\n",
    "We would now proceed to training our entire data with this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nAzTC8wFL79"
   },
   "source": [
    "# **Training on the Entire data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snIIgnrHHSIu"
   },
   "outputs": [],
   "source": [
    "# Assuming Data is your original dataframe\n",
    "# Define SMILES and EXP variables if not defined\n",
    "SMILES = 'SMILES'\n",
    "EXP = 'Active'\n",
    "\n",
    "no_of_fold = 5\n",
    "results = []\n",
    "\n",
    "for i in range(no_of_fold):\n",
    "    # Use the entire dataset for training\n",
    "    train = Data\n",
    "\n",
    "    # Separate features (SMILES) and target variable (EXP) for training\n",
    "    smiles_train = train[SMILES]\n",
    "    y_train = train[EXP]\n",
    "\n",
    "    # Initialize and fit the model: Our best model was\n",
    "    model = lq.ErsiliaBinaryClassifier(time_budget_sec=600, estimator_list=[\"rf\", \"lgbm\", \"xgboost\"])\n",
    "    model.fit(smiles_train, y_train)\n",
    "\n",
    "    # Separate features (SMILES) for testing (you can use the entire dataset or a different dataset for testing)\n",
    "    smiles_test = Data[SMILES]\n",
    "\n",
    "    # Predict probabilities using the trained model\n",
    "    y_hat = model.predict_proba(smiles_test)\n",
    "\n",
    "    # Store the results\n",
    "    results.append(y_hat)\n",
    "\n",
    "# Calculate the mean score\n",
    "mean_score = np.mean(results, axis=0)\n",
    "mean_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAqamZERHwCk"
   },
   "outputs": [],
   "source": [
    "# We need the real results, the activity of the test set\n",
    "y_test = Data['Active']\n",
    "\n",
    "# We use the sklearn package to calculate the roc_curve and plot it\n",
    "y_hat = y_hat[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_hat)\n",
    "auroc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='#50285a', lw=2, label=f'ROC curve (AUC = {auroc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='#bee6b4', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V69tCxpyJC8M"
   },
   "outputs": [],
   "source": [
    "proba_cutoff = 0.5\n",
    "y_hat_bin = [1 if x >= proba_cutoff else 0 for x in y_hat]\n",
    "\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_hat_bin)\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Greens', cbar=False, annot_kws={\"size\": 16})\n",
    "ax.set_title(\"Predicted vs Real\", fontsize=14)\n",
    "ax.set_xlabel('Predicted', fontsize=14)\n",
    "ax.set_ylabel('Real', fontsize=14)\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Inactive','Active'], fontsize=14)\n",
    "ax.yaxis.set_ticklabels(['Inactive','Active'], fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jbf_yQEsJJ3W"
   },
   "outputs": [],
   "source": [
    "model.save(\"model_eosce_full600.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxSp9tkaSZ-f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
